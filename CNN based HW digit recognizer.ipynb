{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nimport datetime\n\"\"\"\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\"\"\"\n\n# Any results you write to the current directory are saved as output.","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"# Importing necessary libraries\nimport glob\nimport pickle\nimport cv2\nimport pydot\nfrom IPython.display import SVG\nfrom sklearn.model_selection import train_test_split\nimport keras\nfrom keras import backend as k\nfrom keras.models import Sequential\nfrom keras.models import Model\nfrom keras.layers import Dense, Input, Conv2D, Flatten, MaxPooling2D, Activation, Dropout\nfrom keras.optimizers import RMSprop, Adam\nfrom keras.utils import to_categorical\nfrom keras.utils.vis_utils import model_to_dot\nfrom keras.utils import plot_model\nfrom keras.callbacks import ModelCheckpoint\nfrom keras.callbacks import ReduceLROnPlateau\nimport matplotlib.pyplot as plt\n%matplotlib inline","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Declaring constants\nFIG_WIDTH=20 # Width of figure\nHEIGHT_PER_ROW=3 # Height of each row when showing a figure which consists of multiple rows\nRESIZE_DIM=28 # The images will be resized to 28x28 pixels","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Setting up the training and test set directories"},{"metadata":{"trusted":true},"cell_type":"code","source":"data_dir=os.path.join('..','input/numta')\npaths_train_a=glob.glob(os.path.join(data_dir,'training-a','*.png'))\npaths_train_b=glob.glob(os.path.join(data_dir,'training-b','*.png'))\npaths_train_e=glob.glob(os.path.join(data_dir,'training-e','*.png'))\npaths_train_c=glob.glob(os.path.join(data_dir,'training-c','*.png'))\npaths_train_d=glob.glob(os.path.join(data_dir,'training-d','*.png'))\npaths_train_all=paths_train_a+paths_train_b+paths_train_c+paths_train_d+paths_train_e","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"paths_test_a=glob.glob(os.path.join(data_dir,'testing-a','*.png'))\npaths_test_b=glob.glob(os.path.join(data_dir,'testing-b','*.png'))\npaths_test_e=glob.glob(os.path.join(data_dir,'testing-e','*.png'))\npaths_test_c=glob.glob(os.path.join(data_dir,'testing-c','*.png'))\npaths_test_d=glob.glob(os.path.join(data_dir,'testing-d','*.png'))\npaths_test_f=glob.glob(os.path.join(data_dir,'testing-f','*.png'))+glob.glob(os.path.join(data_dir,'testing-f','*.JPG'))\npaths_test_auga=glob.glob(os.path.join(data_dir,'testing-auga','*.png'))\npaths_test_augc=glob.glob(os.path.join(data_dir,'testing-augc','*.png'))\npaths_test_all=paths_test_a+paths_test_b+paths_test_c+paths_test_d+paths_test_e+paths_test_f+paths_test_auga+paths_test_augc","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"path_label_train_a=os.path.join(data_dir,'training-a.csv')\npath_label_train_b=os.path.join(data_dir,'training-b.csv')\npath_label_train_e=os.path.join(data_dir,'training-e.csv')\npath_label_train_c=os.path.join(data_dir,'training-c.csv')\npath_label_train_d=os.path.join(data_dir,'training-d.csv')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Getting the Helper functions ready"},{"metadata":{"trusted":true},"cell_type":"code","source":"def get_key(path):\n    '''yields the key of an image from the filepath\n    Args:\n        path: The full path directory of an image\n    Returns:\n        key: The identifier of the image'''\n    key=path.split(sep=os.sep)[-1]\n    return key","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def get_data(paths_img,path_label=None,resize_dim=None):\n    '''reads images from the filepaths, resizes them (if given), and returns them in a numpy array\n    Args:\n        paths_img: image filepaths\n        path_label: pass image label filepaths while processing training data, defaults to None while processing testing data\n        resize_dim: if given, the image is resized to resize_dim x resize_dim (optional)\n    Returns:\n        X: group of images\n        y: categorical true labels\n    '''\n    X=[] # initialize empty list for resized images\n    for i,path in enumerate(paths_img):\n        img=cv2.imread(path,cv2.IMREAD_COLOR) # images loaded in color (BGR)\n        #img = cv2.fastNlMeansDenoisingColored(img,None,10,10,7,21)\n        img=cv2.cvtColor(img,cv2.COLOR_BGR2GRAY) # cnahging colorspace to GRAY\n        if resize_dim is not None:\n            img=cv2.resize(img,(resize_dim,resize_dim),interpolation=cv2.INTER_AREA) # resize image to 28x28\n        #X.append(np.expand_dims(img,axis=2)) # expand image to 28x28x1 and append to the list.\n        gaussian_3 = cv2.GaussianBlur(img, (9,9), 10.0) #unblur\n        img = cv2.addWeighted(img, 1.5, gaussian_3, -0.5, 0, img)\n        kernel = np.array([[-1,-1,-1], [-1,9,-1], [-1,-1,-1]]) #filter\n        img = cv2.filter2D(img, -1, kernel)\n        thresh = 200\n        maxValue = 255\n        #th, img = cv2.threshold(img, thresh, maxValue, cv2.THRESH_BINARY);\n        ret,img = cv2.threshold(img, 0, 255, cv2.THRESH_BINARY+cv2.THRESH_OTSU)\n        X.append(img) # expand image to 28x28x1 and append to the list\n        # display progress\n        if i==len(paths_img)-1:\n            end='\\n'\n        else: end='\\r'\n        print('processed {}/{}'.format(i+1,len(paths_img)),end=end)\n        \n    X=np.array(X) # tranform list to numpy array\n    if  path_label is None:\n        return X\n    else:\n        df = pd.read_csv(path_label) # read labels\n        df=df.set_index('filename') \n        y_label=[df.loc[get_key(path)]['digit'] for path in  paths_img] # get the labels corresponding to the images\n        y=to_categorical(y_label,10) # transfrom integer value to categorical variable\n        return X, y","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def imshow_group(X,y,y_pred=None,n_per_row=10,phase='processed'):\n    '''helper function to visualize a group of images along with their categorical true labels (y) and prediction probabilities.\n    Args:\n        X: images\n        y: categorical true labels\n        y_pred: predicted class probabilities\n        n_per_row: number of images per row to be plotted\n        phase: If the images are plotted after resizing, pass 'processed' to phase argument. \n            It will plot the image and its true label. If the image is plotted after prediction \n            phase, pass predicted class probabilities to y_pred and 'prediction' to the phase argument. \n            It will plot the image, the true label, and it's top 3 predictions with highest probabilities.\n    '''\n    n_sample=len(X)\n    img_dim=X.shape[1]\n    j=np.ceil(n_sample/n_per_row)\n    fig=plt.figure(figsize=(FIG_WIDTH,HEIGHT_PER_ROW*j))\n    for i,img in enumerate(X):\n        plt.subplot(j,n_per_row,i+1)\n#         img_sq=np.squeeze(img,axis=2)\n#         plt.imshow(img_sq,cmap='gray')\n        plt.imshow(img)\n        if phase=='processed':\n            plt.title(np.argmax(y[i]))\n        if phase=='prediction':\n            top_n=3 # top 3 predictions with highest probabilities\n            ind_sorted=np.argsort(y_pred[i])[::-1]\n            h=img_dim+4\n            for k in range(top_n):\n                string='pred: {} ({:.0f}%)\\n'.format(ind_sorted[k],y_pred[i,ind_sorted[k]]*100)\n                plt.text(img_dim/2, h, string, horizontalalignment='center',verticalalignment='center')\n                h+=4\n            if y is not None:\n                plt.text(img_dim/2, -4, 'true label: {}'.format(np.argmax(y[i])), \n                         horizontalalignment='center',verticalalignment='center')\n        plt.axis('off')\n    plt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def create_submission(predictions,keys,path):\n    \"\"\"\n    Args: prediction - Numpy array of predictions on the test set\n          keys - The keys of the test images\n          path - Output directory of the submission file\n    \"\"\"\n    result = pd.DataFrame(\n        predictions,\n        columns=['label'],\n        index=keys\n        )\n    result.index.name='key'\n    result.to_csv(path, index=True)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Data Preprocessing"},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train_a,y_train_a=get_data(paths_train_a,path_label_train_a,resize_dim=RESIZE_DIM)\nX_train_b,y_train_b=get_data(paths_train_b,path_label_train_b,resize_dim=RESIZE_DIM)\nX_train_c,y_train_c=get_data(paths_train_c,path_label_train_c,resize_dim=RESIZE_DIM)\nX_train_d,y_train_d=get_data(paths_train_d,path_label_train_d,resize_dim=RESIZE_DIM)\nX_train_e,y_train_e=get_data(paths_train_e,path_label_train_e,resize_dim=RESIZE_DIM)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train_all=np.concatenate((X_train_a,X_train_b,X_train_c,X_train_d,X_train_e),axis=0)\ny_train_all=np.concatenate((y_train_a,y_train_b,y_train_c,y_train_d,y_train_e),axis=0)\nX_train_all.shape, y_train_all.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_test_a=get_data(paths_test_a,resize_dim=RESIZE_DIM)\nX_test_b=get_data(paths_test_b,resize_dim=RESIZE_DIM)\nX_test_c=get_data(paths_test_c,resize_dim=RESIZE_DIM)\nX_test_d=get_data(paths_test_d,resize_dim=RESIZE_DIM)\nX_test_e=get_data(paths_test_e,resize_dim=RESIZE_DIM)\nX_test_f=get_data(paths_test_f,resize_dim=RESIZE_DIM)\nX_test_auga=get_data(paths_test_auga,resize_dim=RESIZE_DIM)\nX_test_augc=get_data(paths_test_augc,resize_dim=RESIZE_DIM)\nX_test_all=np.concatenate((X_test_a,X_test_b,X_test_c,X_test_d,X_test_e,X_test_f,X_test_auga,X_test_augc))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_tshow_all=X_test_all\nX_tshow_all.shape\n\n# reshaping the data to dim - (number of samples, img_height, img_width, no_of_channels)\nX_train_all = X_train_all.reshape(-1, 28, 28,1).astype('float32')\nX_test_all = X_test_all.reshape(-1, 28, 28,1).astype('float32')\n\nX_train_all.shape\n\n# normalizing the input\nX_train_all = X_train_all / 255\nX_test_all = X_test_all / 255","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# segregating trainig set and dev set\n\n\"\"\"indices=list(range(len(X_train_all)))\nnp.random.seed(42)\nnp.random.shuffle(indices)\n\nind=int(len(indices)*0.80)\n\n# train data\nX_train=X_train_all[indices[:ind]] \ny_train=y_train_all[indices[:ind]]\n\n# validation data\nX_val=X_train_all[indices[-(len(indices)-ind):]] \ny_val=y_train_all[indices[-(len(indices)-ind):]]\"\"\"\n\nX_train, X_val, Y_train, Y_val = train_test_split(X_train_all, y_train_all, test_size = 0.15, random_state=2)\n\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Model Development"},{"metadata":{"trusted":true},"cell_type":"code","source":"'''the architecture is quite similar to classic LeNet with 2 consecutive convolution layers followed by a poolig layer and repeat the same for 3 times before \nflattening the array and fed it into a fully connected archritecture'''\n\ndef my_model(img_size, channels):\n    \n    model = Sequential()\n    input_shape = (img_size,img_size,channels)\n    \n    model.add(Conv2D(filters=32, kernel_size=(5, 5), input_shape=input_shape, activation='relu', padding='same'))\n    model.add(Conv2D(filters=32, kernel_size=(5, 5), activation='relu', padding='same'))\n    model.add(MaxPooling2D(pool_size=(2, 2)))\n    model.add(Dropout(0.25))\n    \n    model.add(Conv2D(filters = 64, kernel_size = (3,3), padding = 'Same', activation ='relu'))\n    model.add(Conv2D(filters = 64, kernel_size = (3,3), padding = 'Same', activation ='relu'))\n    model.add(MaxPooling2D(pool_size=(2,2), strides=(2,2)))\n    model.add(Dropout(0.25))\n    \n    model.add(Flatten())\n    model.add(Dense(256, activation = \"relu\"))\n    model.add(Dropout(0.5))\n    model.add(Dense(10, activation = \"softmax\"))    \n    \n    model.compile(loss='categorical_crossentropy', metrics=['accuracy'],optimizer='adam')\n    # UNCOMMENT THIS TO VIEW THE ARCHITECTURE\n    #model.summary()\n    \n    return model","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model=my_model(28, 1)\nmodel.summary()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plot_model(model, to_file='Bangla_HW_digit_recognition.png')\nSVG(model_to_dot(model).create(prog='dot', format='svg'))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Training & Validation"},{"metadata":{"trusted":true},"cell_type":"code","source":"# saving the architecture and the parameters of the model\npath_model='model_filter.h5' # save model at this location after each epoch","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# destroys the current graph and builds a new one\n#k.tensorflow_backend.clear_session()\n\nmodel.compile(optimizer = 'adam' , loss = \"categorical_crossentropy\", metrics=[\"accuracy\"])\nepochs = 30\nbatch_size = 64\nlearning_rate_reduction = ReduceLROnPlateau(monitor='val_accuracy', \n                                            patience=3, \n                                            verbose=1, \n                                            factor=0.5, \n                                            min_lr=0.00001)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# destroys the current graph and builds a new one\nk.tensorflow_backend.clear_session() \n\n# create the model\nmodel=my_model(28, 1)\n\n# set the learning rate\nk.set_value(model.optimizer.lr,1e-3) \n\n# fit the model\nfinal = model.fit(x=X_train, y=Y_train, batch_size = batch_size, epochs = epochs, validation_data = (X_val, Y_val), shuffle=True, callbacks=[ModelCheckpoint(filepath=path_model), learning_rate_reduction])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_sample = X_train_a[:40]\nY_sample = y_train_a[:40]\n\nimshow_group(X=X_sample,y=Y_sample,phase='processed')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_sample = X_test_a[:40]\n\nimshow_group(X=X_sample, y=None, y_pred=predictions, phase='prediction')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# making prediction on a subset of data\ndev_predict = model.predict(X_train_a.reshape(-1, 28, 28,1).astype('float32'))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# get the indice of the images which were incorrectly labeled\nincorrect_ind=[]\nfor i,pred in enumerate(predictions):\n    if np.argmax(y_train_a[i])!=np.argmax(pred):\n        incorrect_ind.append(i)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# let's observe some samples of the incorrectly classified data\nX_inc=X_train_a[incorrect_ind[:40]]\ny_inc=predictions[incorrect_ind[:40]]\ny_true=y_train_a[incorrect_ind[:40]]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"imshow_group(X=X_inc,y=y_true,y_pred=y_inc, phase='prediction')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Inferencing on the test set"},{"metadata":{"trusted":true},"cell_type":"code","source":"# get predictions for all the test data\npredictions=model.predict(X_test_all)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# **Submission**"},{"metadata":{"trusted":true},"cell_type":"code","source":"# select the index with the maximum probability\nresults = np.argmax(predictions,axis = 1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# get the keys of all test images\nkeys=[get_key(path) for path in paths_test_all]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# get the current time and add it to the submission filename, helps to keep track of submissions\ncurrent_time = datetime.datetime.now().strftime('%Y-%m-%d-%H-%M')\nflname_sub = 'submission_' + current_time + '_'+'.csv' # submission file name\nflname_sub","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"create_submission(results,keys,flname_sub)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Let's load the submission and display it\npd.read_csv(flname_sub)","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}